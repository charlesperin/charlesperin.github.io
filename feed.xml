<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2026-02-27T15:12:50+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Charles Perin</title><subtitle>Charles Perin Homepage</subtitle><entry><title type="html">Workshop on Craft-Based Data Physicalization: Opportunities and Challenges</title><link href="http://localhost:4000/workshop/craftphysworkshop" rel="alternate" type="text/html" title="Workshop on Craft-Based Data Physicalization: Opportunities and Challenges" /><published>2026-04-01T02:00:00+02:00</published><updated>2026-04-01T02:00:00+02:00</updated><id>http://localhost:4000/workshop/craftphysworkshop</id><content type="html" xml:base="http://localhost:4000/workshop/craftphysworkshop"><![CDATA[]]></content><author><name>bakhtiari</name></author><category term="workshop" /><category term="physicalization" /><category term="craft" /><summary type="html"><![CDATA[We invite data visualization, HCI, and craft researchers and practitioners who are interested in topics related to data physicalization to submit short statements of interest (e.g., 500 words) accompanied by visuals of craft techniques used for representing data, or how they would envision doing so. Our goal is to gather researchers and practitioners to establish a research agenda on opportunities and challenges of representing data through craft practices. Our workshop will be three hours long and held in person. In the workshop, participants will engage in hands-on group activities of representing data using different craft techniques. The hands-on activities will be followed by discussions among group members and then among all participants in the workshop to discuss opportunities and challenges in data encoding, the impact on the authoring process, tensions between aesthetics and accuracy, and implications of slow practices. Finally, participants will discuss how we could design systems and processes to support craft practitioners in using their medium to represent data.]]></summary></entry><entry><title type="html">Design Exploration of AI-assisted Personal Affective Physicalization</title><link href="http://localhost:4000/publications/AI_assisted_affective_physicalization" rel="alternate" type="text/html" title="Design Exploration of AI-assisted Personal Affective Physicalization" /><published>2026-01-01T01:00:00+01:00</published><updated>2026-01-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/AI_assisted_affective_physicalization</id><content type="html" xml:base="http://localhost:4000/publications/AI_assisted_affective_physicalization"><![CDATA[]]></content><author><name>wuruishan</name></author><category term="publications" /><category term="Affect" /><category term="Physicalization" /><summary type="html"><![CDATA[Personal affective physicalization is the process by which individuals express emotions through tangible forms to record, reflect on, and communicate. Yet such physical data representations can be challenging to design due to the abstract nature of emotions. Given the shown potential of AI in detecting emotion and assisting design, we explore opportunities in AI-assisted design of personal affective physicalization using a research-through-design method. We developed PhEmotion, a tool for embedding LLM-extracted emotion values from human–AI conversations into the parametric design of physical artifacts. A lab study was conducted with 14 participants creating these artifacts based on their personal emotions, with and without AI support. We observed nuances and variations in participants’ creative strategies, meaning-making processes, and their perceptions of AI support in this context. We found key tensions in AI–human cocreation that provide a nuanced agenda for future research in AI-assisted personal affective physicalization.]]></summary></entry><entry><title type="html">Running with Data: A Survey of the Current Research and a Design Exploration of Future Immersive Visualisations</title><link href="http://localhost:4000/publications/running_with_data" rel="alternate" type="text/html" title="Running with Data: A Survey of the Current Research and a Design Exploration of Future Immersive Visualisations" /><published>2026-01-01T01:00:00+01:00</published><updated>2026-01-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/running_with_data</id><content type="html" xml:base="http://localhost:4000/publications/running_with_data"><![CDATA[]]></content><author><name>liang</name></author><category term="publications" /><category term="Running" /><category term="immersive Visualization" /><summary type="html"><![CDATA[This work investigates the current research on in-situ visualisations for running: visualisations about data that are referred to during the running activity. We analyse 47 papers from 33 Human-Computer Interaction and Visualisation venues and identify six dimensions of a design space of in-situ running visualisations. Our analysis of this design space highlights an emerging trend: a shift from on-body, peripersonal visualisations (i.e., in the space within direct reach, such as visualisations on a smartwatch or a mobile phone display) towards extrapersonal displays (i.e., in the space beyond immediate reach, such as visualisations in immersive augmented reality displays) that integrate data in the runner's surrounding environment. We explore this opportunity by conducting a series of workshops with 10 active runners in total, eliciting design concepts for running visualisations and interactions beyond conventional 2D displays. We find that runners show a strong interest for visualisation designs that favour more context-aware, interactive, and unobtrusive experiences that seamlessly integrate with their run. These finding inform a set of design considerations for future immersive running visualisations and highlight directions for further research.]]></summary></entry><entry><title type="html">VISMOCK: A Programmable Smocking Technique for Creating Interactive Data Physicalization</title><link href="http://localhost:4000/publications/vismock-poster" rel="alternate" type="text/html" title="VISMOCK: A Programmable Smocking Technique for Creating Interactive Data Physicalization" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/vismock-poster</id><content type="html" xml:base="http://localhost:4000/publications/vismock-poster"><![CDATA[]]></content><author><name>bakhtiari</name></author><category term="publications" /><category term="TAG1" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ThreadWave: Visualizing Co-authorship as Temporal Threads</title><link href="http://localhost:4000/publications/threadwave-poster" rel="alternate" type="text/html" title="ThreadWave: Visualizing Co-authorship as Temporal Threads" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/threadwave-poster</id><content type="html" xml:base="http://localhost:4000/publications/threadwave-poster"><![CDATA[]]></content><author><name>wuruishan</name></author><category term="publications" /><category term="TAG1" /><summary type="html"><![CDATA[We present a timeline-based visualization for exploring temporal collaboration patterns among academic authors. Inspired by the metaphors of weaving threads and ripple waves, our technique represents each author as a colored baseline and uses curved connectors to show co-authorship events over time.]]></summary></entry><entry><title type="html">Repeated Actions in Fabric Manipulation Crafts as an Opportunity for Input Physicalization</title><link href="http://localhost:4000/publications/repeated_actions_vismock" rel="alternate" type="text/html" title="Repeated Actions in Fabric Manipulation Crafts as an Opportunity for Input Physicalization" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/repeated_actions_vismock</id><content type="html" xml:base="http://localhost:4000/publications/repeated_actions_vismock"><![CDATA[]]></content><author><name>bakhtiari</name></author><category term="publications" /><category term="tag" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Noticing as Visualization Practice: Discovering Data in the Everyday</title><link href="http://localhost:4000/publications/noticing-poster" rel="alternate" type="text/html" title="Noticing as Visualization Practice: Discovering Data in the Everyday" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/noticing-poster</id><content type="html" xml:base="http://localhost:4000/publications/noticing-poster"><![CDATA[]]></content><author><name>daneshzand</name></author><category term="publications" /><category term="TAG1" /><summary type="html"><![CDATA[We introduce noticing as a creative methodology for visualization design, cultivating perceptual sensitivity to the subtle encodings in everyday phenomena. Natural and human-made elements—shapes, textures, sounds, and transformations—carry latent data mappings that, when attended to with curiosity, reveal hidden data stories. This methodology redefines what counts as data, extending beyond structured sources to embrace the inherent information in our surroundings. Rather than imposing external structures, noticing foregrounds the world’s intrinsic ways of organizing and presenting information, inspiring novel metaphors, supporting embodied data experiences, and fostering more critical and creative relationships with information.]]></summary></entry><entry><title type="html">The Fuzzy Front Ends: Reflections on the Never-Ending Story of Visualization Co-Design</title><link href="http://localhost:4000/publications/fuzzy_front_ends" rel="alternate" type="text/html" title="The Fuzzy Front Ends: Reflections on the Never-Ending Story of Visualization Co-Design" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/fuzzy_front_ends</id><content type="html" xml:base="http://localhost:4000/publications/fuzzy_front_ends"><![CDATA[]]></content><author><name>weiwei</name></author><category term="publications" /><category term="tag" /><summary type="html"><![CDATA[Co-design is an increasingly popular approach in HCI and visualization, yet there is little guidance on how to effectively apply this method in visualization contexts. In this paper, we visually present our experience of a two-and-a-half-year co-design project with the local arts community. Focusing on facilitating community exploration and sense-making around arts funding distribution, the project involved a series of co-design sessions between visualization researchers and members of the arts community. Through these iterative sessions, we built shared understanding and developed visualization prototypes tailored to community needs. However, the practice is far from complete, and we found ourselves continually returning to the “fuzzy front end” of the co-design process. We share this ongoing story through comic-style visuals and reflect on three fuzzy front ends that we encountered during the project. By sharing these experiences with the visualization community, we hope to offer insights that others can draw on in their own community-engaged co-design work.]]></summary></entry><entry><title type="html">FlexPhys: A Workshop Cookbook for Operationalizing Data Physicalization Research Questions</title><link href="http://localhost:4000/publications/flexphys" rel="alternate" type="text/html" title="FlexPhys: A Workshop Cookbook for Operationalizing Data Physicalization Research Questions" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/flexphys</id><content type="html" xml:base="http://localhost:4000/publications/flexphys"><![CDATA[]]></content><author><name>bakhtiari</name></author><category term="publications" /><category term="Workshop" /><category term="Physicalization" /><summary type="html"><![CDATA[We introduce FlexPhys, a cookbook that researchers can use to operationalize data physicalization research questions through workshop design. While guidelines exist for running workshops in educational contexts, designing a data physicalization workshop when the goal is to answer research questions is an ad-hoc process for which little guidance exists, but for which many choices must be made (e.g., in terms of materials, tools, and data). We draw from our experience designing data physicalization workshops and from reviewing three existing workshops, to distill the cookbook's core ingredient (context and goal) and eight additional ingredients related to making (material, tool, technique), data encoding (data type, variable, mark/unit), and interactivity (interaction, sensory modality). We then show how FlexPhys can be used to describe and compare physicalization workshops, and to generate workshops that address specific data physicalization research questions.]]></summary></entry><entry><title type="html">Physically encoding data with material flexibility</title><link href="http://localhost:4000/publications/flexibility-poster" rel="alternate" type="text/html" title="Physically encoding data with material flexibility" /><published>2025-11-01T01:00:00+01:00</published><updated>2025-11-01T01:00:00+01:00</updated><id>http://localhost:4000/publications/flexibility-poster</id><content type="html" xml:base="http://localhost:4000/publications/flexibility-poster"><![CDATA[]]></content><author><name>bakhtiari</name></author><category term="publications" /><category term="TAG1" /><summary type="html"><![CDATA[Data physicalizations utilize non-visual sensory modalities to encode data. There is a need to study how different material properties affect user interaction and perception with physicalizations. In this work, we investigate how material flexibility can be used to encode data, by studying i) how people interact with flexible material for understanding data and ii) how they perceive flexibility to decode encoded data values.]]></summary></entry></feed>